{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair Binary Classification with SearchFair on CelebA and Adult\n",
    "\n",
    "Here, we show how to use SearchFair on two datasets: CelebA and Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We start by importing SearchFair from the installed package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchfair import SearchFair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we load some necessary methods and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# The optimization does not always comply with the new cvxpy dpp disciplined programming rules. \n",
    "# but this is not a problem. \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CelebA dataset\n",
    "\n",
    "On the Celebrity Faces dataset we are given descriptions of celebrity faces, with 40 binary attributes. Here, we use the Attribute 'Smiling' as the class label, and sex as the sensitive attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_real_data as get_data\n",
    "\n",
    "# Load Data\n",
    "x_data, y_data, s_data = get_data.get_celebA_data(load_data_size=None)\n",
    "# Train Test split. Here, we choose a small number to reduce running time.\n",
    "train_size = 1200\n",
    "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=train_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some basic information about the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
       "       -1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1, -1,  1, -1,\n",
       "        1, -1, -1,  1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[:10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1,  1, -1,  1, -1,  1, -1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, -1,  1, -1,  1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 202599\n",
      "# non-protected examples: 118165\n",
      "# protected examples: 84434\n",
      "# non-protected examples in positive class: 63871 (54.1%)\n",
      "# protected examples in positive class: 33798 (40.0%)\n"
     ]
    }
   ],
   "source": [
    "import utils as ut\n",
    "ut.print_data_stats(s_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a SearchFair Model\n",
    "\n",
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn a classifier with SearchFair, we need to choose a kernel between 'linear' and 'rbf', and we need to choose a fairness notion - either Demographic Parity (DDP) or Equality of Opportunity (DEO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_notion = 'DDP' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'linear' # 'linear', 'rbf'\n",
    "verbose = True # True = SearchFair output, 2 = show also solver progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us choose a regularization parameter and then fit a model with the default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Testing lambda_min: 0.00\n",
      "Obtained: DDP = 0.2434 with lambda = 0.0000\n",
      "Testing lambda_max: 1.00\n",
      "Obtained: DDP = -0.8049 with lambda = 1.0000\n",
      "Starting Binary Search...\n",
      "----------Iteration #0----------\n",
      "Testing new Lambda: 0.5000\n",
      "Obtained: DDP = -0.5025 with lambda = 0.5000\n",
      "----------Iteration #1----------\n",
      "Testing new Lambda: 0.2500\n",
      "Obtained: DDP = 0.0422 with lambda = 0.2500\n",
      "----------Iteration #2----------\n",
      "Testing new Lambda: 0.3750\n",
      "Obtained: DDP = -0.2348 with lambda = 0.3750\n",
      "----------Iteration #3----------\n",
      "Testing new Lambda: 0.3125\n",
      "Obtained: DDP = 0.0422 with lambda = 0.3125\n",
      "----------Iteration #4----------\n",
      "Testing new Lambda: 0.3438\n",
      "Obtained: DDP = -0.0795 with lambda = 0.3438\n",
      "----------Iteration #5----------\n",
      "Testing new Lambda: 0.3281\n",
      "Obtained: DDP = 0.0143 with lambda = 0.3281\n",
      "----------Iteration #6----------\n",
      "Testing new Lambda: 0.3359\n",
      "Obtained: DDP = -0.0701 with lambda = 0.3359\n",
      "----------Iteration #7----------\n",
      "Testing new Lambda: 0.3320\n",
      "Obtained: DDP = -0.0267 with lambda = 0.3320\n",
      "----------Iteration #8----------\n",
      "Testing new Lambda: 0.3301\n",
      "Obtained: DDP = -0.0190 with lambda = 0.3301\n",
      "----------Iteration #9----------\n",
      "Testing new Lambda: 0.3291\n",
      "Obtained: DDP = -0.0190 with lambda = 0.3291\n",
      "Hit maximum iterations of Binary Search.\n",
      "----------Found Lambda 0.3281 with fairness 0.0143----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SearchFair(reg_beta=0.0001, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularization Parameter beta\n",
    "reg_beta = 0.0001\n",
    "linear_model_DDP = SearchFair(reg_beta=reg_beta, kernel=kernel, fairness_notion=fairness_notion, verbose=verbose, stop_criterion=0.01)\n",
    "linear_model_DDP.fit(x_train, y_train, s_train=s_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print out the Accuracy and the fairness notions Demographic Parity and Equality of Opportuniy, we define the following function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clf_stats(model, x_train, x_test, y_train, y_test, s_train, s_test):\n",
    "    train_acc = ut.get_accuracy(np.sign(model.predict(x_train)), y_train)\n",
    "    test_acc = ut.get_accuracy(np.sign(model.predict(x_test)), y_test)\n",
    "    test_DDP, test_DEO = ut.compute_fairness_measures(model.predict(x_test), y_test, s_test)\n",
    "    train_DDP, train_DEO = ut.compute_fairness_measures(model.predict(x_train), y_train, s_train)\n",
    "\n",
    "    print(10*'-'+\"Train\"+10*'-')\n",
    "    print(\"Accuracy: %0.4f%%\" % (train_acc * 100))\n",
    "    print(\"DDP: %0.4f%%\" % (train_DDP * 100), \"DEO: %0.4f%%\" % (train_DEO * 100))\n",
    "    print(10*'-'+\"Test\"+10*'-')\n",
    "    print(\"Accuracy: %0.4f%%\" % (test_acc * 100))\n",
    "    print(\"DDP: %0.4f%%\" % (test_DDP * 100), \"DEO: %0.4f%%\" % (test_DEO * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see, if we obtained a fair classifier with respect to the fairness notions we specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Train----------\n",
      "Accuracy: 80.0000%\n",
      "DDP: 1.4287% DEO: 3.9236%\n",
      "----------Test----------\n",
      "Accuracy: 79.5689%\n",
      "DDP: 2.7502% DEO: 11.8037%\n"
     ]
    }
   ],
   "source": [
    "print_clf_stats(linear_model_DDP, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train DDP is small, and SearchFair succeeded to find a fair classifier. The test DDP might or might not be close to 0. This is due to the small number of points which are used to reduce running time for this example notebook. Go ahead and try it with more points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equality of Opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try the same using a more complex rbf kernel, and we try to improve Equality of Opportunity this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Testing lambda_min: 0.00\n",
      "Obtained: DEO = 0.1603 with lambda = 0.0000\n",
      "Testing lambda_max: 1.00\n",
      "Obtained: DEO = -0.8886 with lambda = 1.0000\n",
      "Starting Binary Search...\n",
      "----------Iteration #0----------\n",
      "Testing new Lambda: 0.5000\n",
      "Obtained: DEO = -0.7966 with lambda = 0.5000\n",
      "----------Iteration #1----------\n",
      "Testing new Lambda: 0.2500\n",
      "Obtained: DEO = -0.1373 with lambda = 0.2500\n",
      "----------Iteration #2----------\n",
      "Testing new Lambda: 0.1250\n",
      "Obtained: DEO = 0.0951 with lambda = 0.1250\n",
      "----------Iteration #3----------\n",
      "Testing new Lambda: 0.1875\n",
      "Obtained: DEO = -0.0153 with lambda = 0.1875\n",
      "----------Iteration #4----------\n",
      "Testing new Lambda: 0.1562\n",
      "Obtained: DEO = 0.0851 with lambda = 0.1562\n",
      "----------Iteration #5----------\n",
      "Testing new Lambda: 0.1719\n",
      "Obtained: DEO = 0.0579 with lambda = 0.1719\n",
      "----------Iteration #6----------\n",
      "Testing new Lambda: 0.1797\n",
      "Obtained: DEO = 0.0279 with lambda = 0.1797\n",
      "----------Iteration #7----------\n",
      "Testing new Lambda: 0.1836\n",
      "Obtained: DEO = 0.0168 with lambda = 0.1836\n",
      "----------Iteration #8----------\n",
      "Testing new Lambda: 0.1855\n",
      "Obtained: DEO = -0.0048 with lambda = 0.1855\n",
      "Sufficient fairness obtained before maximum iterations were reached.\n",
      "----------Found Lambda 0.1855 with fairness -0.0048----------\n",
      "----------Train----------\n",
      "Accuracy: 86.4167%\n",
      "DDP: 6.1724% DEO: -0.4809%\n",
      "----------Test----------\n",
      "Accuracy: 83.9339%\n",
      "DDP: 6.5590% DEO: 2.7608%\n"
     ]
    }
   ],
   "source": [
    "fairness_notion = 'DEO' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'rbf' # 'linear', 'rbf'\n",
    "verbose = True\n",
    "\n",
    "# Regularization Parameter beta\n",
    "reg_beta = 0.0001\n",
    "rbf_model_DEO = SearchFair(reg_beta=reg_beta, kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
    "rbf_model_DEO.fit(x_train, y_train, s_train=s_train)\n",
    "\n",
    "# Evaluate model\n",
    "print_clf_stats(rbf_model_DEO, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use GridSearchCV for the regularization paramter beta, and, if used, the width of the rbf kernel. But running this might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 29.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SearchFair(kernel='rbf'), n_jobs=1,\n",
       "             param_grid={'gamma': [0.01, 0.02631578947368421, 0.1],\n",
       "                         'reg_beta': [0.0001, 0.001, 0.01]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_notion = 'DDP' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'rbf' # 'linear', 'rbf'\n",
    "verbose = False\n",
    "\n",
    "cv_model = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
    "\n",
    "# regularization parameter beta\n",
    "beta_params = [0.0001, 0.001, 0.01]\n",
    "cv_params = {'reg_beta': beta_params}\n",
    "\n",
    "if kernel == 'rbf':\n",
    "    n_features = x_data.shape[1]\n",
    "    default_width = 1/n_features\n",
    "    order_of_magn = np.floor(np.log10(default_width))\n",
    "    kernel_widths = [10**(order_of_magn), default_width, 10**(order_of_magn+1)]\n",
    "    cv_params['gamma'] = kernel_widths\n",
    "\n",
    "grid_clf = GridSearchCV(cv_model,cv_params, cv=3, verbose=1, n_jobs=1, scoring='accuracy', refit=True)\n",
    "grid_clf.fit(x_train, y_train, s_train=s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print_clf_stats(grid_clf, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult dataset\n",
    "\n",
    "In the fairness literature, the adult dataset is a very popular dataset. It contains US census data from 1994, where the class label indicates if the income is higher or lower than 50.000$. The binary sensitive attribute here, is the sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x_data, y_data, s_data = get_data.get_adult_data(load_data_size=None)\n",
    "# Train Test split. Here, we choose a small number to reduce running time.\n",
    "train_size = 1200\n",
    "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=train_size, shuffle=True)\n",
    "ut.print_data_stats(s_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can also try SearchFair on Adult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_notion = 'DDP' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'rbf' # 'linear', 'rbf'\n",
    "verbose = False\n",
    "\n",
    "cv_model_adult = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
    "\n",
    "# regularization parameter beta\n",
    "beta_params = [0.0001, 0.001, 0.01]\n",
    "cv_params = {'reg_beta': beta_params}\n",
    "\n",
    "if kernel == 'rbf':\n",
    "    n_features = x_data.shape[1]\n",
    "    default_width = 1/n_features\n",
    "    order_of_magn = np.floor(np.log10(default_width))\n",
    "    kernel_widths = [10**(order_of_magn), default_width, 10**(order_of_magn+1)]\n",
    "    cv_params['gamma'] = kernel_widths\n",
    "\n",
    "grid_clf = GridSearchCV(cv_model_adult,cv_params, cv=3, verbose=1, n_jobs=1, scoring='accuracy')\n",
    "grid_clf.fit(x_train, y_train, s_train=s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print_clf_stats(grid_clf, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
